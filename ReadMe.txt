景区客流量预测模块代码说明书

一、代码说明
	本项目实现的景区客流量预测是随机森林预测模型。

	【项目结构】
	data：存放数据的文件夹

	tasks：任务包，包括：
		create_data_task: 根据天气文件（或者天气数据）和历史客流量文件创建生成数据文件，由于目前还没有完整数据，一旦有了完整数据，无需每次调用该任务，只需日后增加一个函数，在完整数据后增加最新数据。
		forcast_task: 随机森林预测模型，本项目采用的是sklearn开源工具包的RandomForestRegressor

	utils: 工具包，包括：
		holiday_check: 检测某个日期是否是节假日（由于是调用的是开源的API检测，该API只支持2017年以后的日期）
		reader：多种读取文件的实现

	main：主函数，运行该文件即可启动程序，输入输出具体见该函数（可进一步优化）；
			服务器或者cmd命令行启动方法为：在main.py路径下打开命令行，输入： python main.py

二、关于随机森林的简介
【定义】
	用以执行回归和分类任务的多功能机器学习算法，是一种数据降维手段，用于处理缺失值、异常值以及其他数据探索中的重要步骤。

【原理】
	1. 用N来表示训练用例（样本）的个数，M表示特征数目。
	2. 输入特征数目m，用于确定决策树上一个节点的决策结果；其中m应远小于M。
	3. 从N个训练用例（样本）中以有放回抽样的方式，取样N次，形成一个训练集（即bootstrap取样），并用未抽到的用例（样本）作预测，评估其误差。
	4. 对于每一个节点，随机选择m个特征，决策树上每个节点的决定都是基于这些特征确定的。根据这m个特征，计算其最佳的分裂方式。
	5. 每棵树都会完整成长而不会剪枝（Pruning，这有可能在建完一棵正常树状分类器后会被采用）。

【优点】
	1.随机森林算法能解决分类与回归两种类型的问题，并在这两个方面都有相当好的估计表现；
	2.随机森林对于高维数据集的处理能力令人兴奋，它可以处理成千上万的输入变量，并确定最重要的变量，因此被认为是一个不错的降维方法。此外，该模型能够输出变量的重要性程度，这是一个非常便利的功能。下图展示了随机森林对于变量重要性程度的输出形式：
	3.就算存在大量的数据缺失，随机森林也能较好地保持精确性；
	4.当存在分类不平衡的情况时，随机森林能够提供平衡数据集误差的有效方法；
	5.模型的上述性能可以被扩展运用到未标记的数据集中，用于引导无监督聚类、数据透视和异常检测；
	6.随机森林算法中包含了对输入数据的重复自抽样过程，即所谓的bootstrap抽样。这样一来，数据集中大约三分之一将没有用于模型的训练而是用于测试，这样的数据被称为out of bag samples，通过这些样本估计的误差被称为out of bag error。研究表明，这种out of bag方法的与测试集规模同训练集一致的估计方法有着相同的精确程度，因此在随机森林中我们无需再对测试集进行另外的设置。
	7.学习速度快。
【缺点】
	1.随机森林在解决回归问题时并没有像它在分类中表现的那么好，这是因为它并不能给出一个连续型的输出。当进行回归时，随机森林不能够作出超越训练集数据范围的预测，这可能导致在对某些还有特定噪声的数据进行建模时出现过度拟合。
	2.对于许多统计建模者来说，随机森林给人的感觉像是一个黑盒子——你几乎无法控制模型内部的运行，只能在不同的参数和随机种子之间进行尝试。

【核心】：随机
	1. 独立随机抽样：
		每颗树都进行独立的随机抽样，这样保证了每颗树学习到的数据侧重点不一样，保证了树之间的独立性。
	2. 决策分支随机：
		假设数据有20个特征（属性），每次只随机取其中的几个来判断决策条件。假设取4个属性，从这4个特征中来决定当前的决策条件，即忽略其它的特征。取特征的个数，通常不能太小，太小了使得单颗树的精度太低，太大了树之间的相关性会加强，独立性会减弱。通常取总特征的平方根，或者log2(特征数)+1，在scikit-learn的实现中，支持sqrt与log2，而spark还支持onethird(1/3)。
		在N个最好的分裂特征中，随机选择一个进行分裂。
		在结点进行分裂的时候，除了先随机取固定个特征，然后选择最好的分裂属性这种方式，还有一种方式，就是在最好的几个（依然可以指定sqrt与log2)分裂属性中随机选择一个来进行分裂。scikit-learn中实现了两种随机森林算法，一种是RandomForest，另外一种是ExtraTrees，ExtraTrees就是用这种方式。在某些情况下，会比RandomForest精度略高。
